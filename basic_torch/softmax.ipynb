{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "Softmax는 분류 문제에서, 출력층에서 주로 사용되는 활성화 함수이다.<br>\n",
    "Softmax 함수는 입력된 값들의 총합을 1로, 각 값들은 0과 1 사이의 확률 값으로 만드는 특징이 있어, 예측 결과를 여러 클래스에 대한 확률로 해석할 수 있게 해준다. <br>\n",
    "\n",
    "수식은 다음과 같다.\n",
    "\n",
    "$$ Softmax(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}} $$\n",
    "\n",
    "개념적으로는 전혀 어렵지 않지만 매개변수로 사용되는 `dim`에 따라 어떤 축을 기준으로 softmax를 적용할지가 달라지게 된다.<br>\n",
    "아래의 코드에서 살펴보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1.0, 2.0, 3.0], [-1., 0.0, 2.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2차원 matrix에 대해 Softmax를 적용한 결과는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8808, 0.8808, 0.7311],\n",
      "        [0.1192, 0.1192, 0.2689]])\n",
      "tensor([[0.0900, 0.2447, 0.6652],\n",
      "        [0.0420, 0.1142, 0.8438]])\n"
     ]
    }
   ],
   "source": [
    "print(F.softmax(x, dim=0))\n",
    "print(F.softmax(x, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT에 따르면 \"`dim`은 연산을 적용할 차원을 지정한다.\"라고 한다.\n",
    "\n",
    "이에 대해 dim이 0인 경우를 생각해보면, 0번째 차원을 대상으로 연산을 수행한다. <br>\n",
    "이를 다시 말하면 \"행\"을 대상으로 Softmax를 수행한다고 할 수 있다.\n",
    "\n",
    "하지만 `F.softmax(x, dim=0)`의 결과 값을 보면 각 열을 대상으로 Softmax를 취함을 확인할 수 있다.\n",
    "\n",
    "이처럼 `torch` 함수에서 등장하는 `dim`과 `axis`를 문장으로 표현하면 다소 모호함이 존재한다.<br>\n",
    "따라서 `dim`의 명확한 이해를 하기 위해서는 다음과 같은 표현이 적절한 것 같다.\n",
    "\n",
    "\n",
    "**`dim=0`인 경우 0번째 차원에 `:`를 표기하여 연산하겠다.** <br>\n",
    "**`dim=0`인 경우 0번째 차원을 묶어서 연산하겠다.**\n",
    "\n",
    "\n",
    "`dim=0`일 때는 x[:][]에 대해 softmax를 적용한다고 생각하면 된다.\n",
    "이를 반복문처럼 생각하면\n",
    "\n",
    "``` py\n",
    "for i in range(len(x[0])):\n",
    "    softmax(x[:][i])\n",
    "```\n",
    "가 될 것이다.<br>\n",
    "따라서 x의 각 열을 순회하면서 전체 행을 기준으로 Softmax를 수행하게 된다. \n",
    "\n",
    "3차원을 대상으로 Softmax 연산을 확인해 보겠다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.]],\n",
       "\n",
       "        [[ 5.,  7.,  9., 11., 13.],\n",
       "         [15., 17., 19., 21., 23.],\n",
       "         [25., 27., 29., 31., 33.],\n",
       "         [35., 37., 39., 41., 43.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(20).view(1,4,5).float()\n",
    "b = torch.arange(5,45,2).view(1,4,5).float()\n",
    "y = torch.concat((a,b),dim=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.6929e-03, 2.4726e-03, 9.1105e-04, 3.3535e-04, 1.2339e-04],\n",
      "        [4.5398e-05, 1.6701e-05, 6.1442e-06, 2.2603e-06, 8.3153e-07],\n",
      "        [3.0590e-07, 1.1254e-07, 4.1399e-08, 1.5230e-08, 5.6028e-09],\n",
      "        [2.0612e-09, 7.5826e-10, 2.7895e-10, 1.0262e-10, 3.7751e-11]])\n",
      "tensor([[0.9933, 0.9975, 0.9991, 0.9997, 0.9999],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "y_0 = F.softmax(y, dim=0)\n",
    "print(y_0[0])\n",
    "print(y_0[1])\n",
    "\n",
    "print(sum(y_0[:,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0384e-07, 3.0384e-07, 3.0384e-07, 3.0384e-07, 3.0384e-07],\n",
      "        [4.5094e-05, 4.5094e-05, 4.5094e-05, 4.5094e-05, 4.5094e-05],\n",
      "        [6.6925e-03, 6.6925e-03, 6.6925e-03, 6.6925e-03, 6.6925e-03],\n",
      "        [9.9326e-01, 9.9326e-01, 9.9326e-01, 9.9326e-01, 9.9326e-01]])\n",
      "tensor([[9.3572e-14, 9.3572e-14, 9.3572e-14, 9.3572e-14, 9.3572e-14],\n",
      "        [2.0611e-09, 2.0611e-09, 2.0611e-09, 2.0611e-09, 2.0611e-09],\n",
      "        [4.5398e-05, 4.5398e-05, 4.5398e-05, 4.5398e-05, 4.5398e-05],\n",
      "        [9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "y_1 = F.softmax(y, dim=1)\n",
    "print(y_1[0])\n",
    "print(y_1[1])\n",
    "\n",
    "print(sum(y_1[0,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0117, 0.0317, 0.0861, 0.2341, 0.6364],\n",
      "        [0.0117, 0.0317, 0.0861, 0.2341, 0.6364],\n",
      "        [0.0117, 0.0317, 0.0861, 0.2341, 0.6364],\n",
      "        [0.0117, 0.0317, 0.0861, 0.2341, 0.6364]])\n",
      "tensor([[2.9008e-04, 2.1434e-03, 1.5838e-02, 1.1702e-01, 8.6470e-01],\n",
      "        [2.9008e-04, 2.1434e-03, 1.5838e-02, 1.1702e-01, 8.6470e-01],\n",
      "        [2.9008e-04, 2.1434e-03, 1.5838e-02, 1.1702e-01, 8.6470e-01],\n",
      "        [2.9008e-04, 2.1434e-03, 1.5838e-02, 1.1702e-01, 8.6470e-01]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "y_2 = F.softmax(y, dim=2)\n",
    "print(y_2[0])\n",
    "print(y_2[1])\n",
    "\n",
    "print(sum(y_2[0,0,:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
